{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dNcs9zeHB-Og",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import important libraries"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9JVfhq-9NjtY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1adae383-636e-479c-9e72-2aa9d6554125"
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import keras\n",
        "import multiprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from keras import losses, models, optimizers\n",
        "from keras.layers import Dense, Input, Convolution2D, BatchNormalization, Flatten, MaxPool2D, Activation, Reshape, Dropout\n",
        "from keras.utils import plot_model, Sequence\n",
        "from keras.layers.merge import concatenate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jpI7UeAfB-Or",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Class for dumping and loading pickle files of exceedingly large sizes\n",
        "\n",
        "Reads data byte by byte and writes data byte by byte"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "s5ANurNQN8rb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MacOSFile(object):\n",
        "\n",
        "    def __init__(self, f):\n",
        "        self.f = f\n",
        "\n",
        "    def __getattr__(self, item):\n",
        "        return getattr(self.f, item)\n",
        "\n",
        "    def read(self, n):\n",
        "        if n >= (1 << 31):\n",
        "            buffer = bytearray(n)\n",
        "            idx = 0\n",
        "            while idx < n:\n",
        "                batch_size = min(n - idx, 1 << 31 - 1)\n",
        "                buffer[idx:idx + batch_size] = self.f.read(batch_size)\n",
        "                idx += batch_size\n",
        "            return buffer\n",
        "        return self.f.read(n)\n",
        "\n",
        "    def write(self, buffer):\n",
        "        n = len(buffer)\n",
        "        print(\"writing total_bytes=%s...\" % n, flush=True)\n",
        "        idx = 0\n",
        "        while idx < n:\n",
        "            batch_size = min(n - idx, 1 << 31 - 1)\n",
        "            print(\"writing bytes [%s, %s)... \" % (idx, idx + batch_size), end=\"\", flush=True)\n",
        "            self.f.write(buffer[idx:idx + batch_size])\n",
        "            print(\"done.\", flush=True)\n",
        "            idx += batch_size\n",
        "\n",
        "\n",
        "def pickle_dump(obj, file_path):\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        return pickle.dump(obj, MacOSFile(f), protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "def pickle_load(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        return pickle.load(MacOSFile(f))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmX-0m08B-Ox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mount google drive in colab"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "twk2jLKgOk46",
        "outputId": "7546245e-b49c-4c37-bdb7-0ffe95de2a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uc2KbXXAB-O5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the augmented dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NVEcBMTURBWP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = pickle_load('/content/gdrive/My Drive/MIDAS-CV-TASK/dataset_large.pkl')\n",
        "X_train = dataset['X_train']\n",
        "y_train = dataset['y_train']\n",
        "X_val = dataset['X_val']\n",
        "y_val = dataset['y_val']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbMtdVYBB-O_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construct Batch Generator for training the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cYJLH9sVRRnS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MiniBatchGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, X, y) :\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = 64\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        self.input = []\n",
        "        self.output = []\n",
        "\n",
        "        start = index * self.batch_size\n",
        "        end = min((index + 1) * self.batch_size, self.X.shape[0])\n",
        "        pos = 0\n",
        "        for i in range(start, end):\n",
        "            self.input.append(self.X[i])\n",
        "            self.output.append(self.y[i])\n",
        "            pos += 1\n",
        "\n",
        "        return np.array(self.input), np.array(self.output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_QdCRK7zB-PE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model definition "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TqchjnByRbD7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_definition(learning_rate):\n",
        "\n",
        "    input = Input(shape=(28, 28, 1))\n",
        "\n",
        "    x = (Convolution2D(32, (3, 3), padding=\"same\", input_shape=(28, 28, 1)))(input)\n",
        "    x = (BatchNormalization())(x)\n",
        "    x = (Activation('relu'))(x)\n",
        "    x = (MaxPool2D())(x)\n",
        "    \n",
        "    x = (Dropout(0.25))(x)\n",
        "    \n",
        "    x = (Convolution2D(64, (3, 3), padding=\"same\"))(x)\n",
        "    x = (BatchNormalization())(x)\n",
        "    x = (Activation('relu'))(x)\n",
        "    \n",
        "    x = (MaxPool2D())(x)\n",
        "    x = (Dropout(0.25))(x)\n",
        "    \n",
        "    x = (Convolution2D(128, (3, 3), padding=\"same\"))(x)\n",
        "    x = (BatchNormalization())(x)\n",
        "    x = (Activation('relu'))(x)\n",
        "    \n",
        "    x = (Dropout(0.4))(x)\n",
        "\n",
        "    x = (Flatten())(x)\n",
        "    \n",
        "    x = (Dense(256, activation='relu'))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = (Dropout(0.5))(x)\n",
        "\n",
        "    x = (Dense(64, activation='relu'))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = (Dropout(0.4))(x)\n",
        "\n",
        "    x = (Dense(16, activation='relu'))(x)\n",
        "    x = (Dropout(0.3))(x)\n",
        "\n",
        "    output = (Dense(4, activation='softmax'))(x)\n",
        "\n",
        "    model = models.Model(inputs=input, outputs=output)\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
        "\n",
        "    plot_model(model, to_file='/content/gdrive/My Drive/MIDAS-CV-TASK/model.png', show_layer_names=True, show_shapes=True)\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "88suGISEB-PJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the training and validation batch generators."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Py8YNX1GRc8V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_gen = MiniBatchGenerator(X_train, y_train)\n",
        "val_gen = MiniBatchGenerator(X_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KiFfgCzqB-PQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the model. You can also see the model architecture that I have printed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9CULXul3Re-f",
        "outputId": "d4af4a0c-ecf2-46e5-f804-233b75ee4c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        }
      },
      "cell_type": "code",
      "source": [
        "model = model_definition(0.001)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               1605888   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 68        \n",
            "=================================================================\n",
            "Total params: 1,718,292\n",
            "Trainable params: 1,717,204\n",
            "Non-trainable params: 1,088\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V0dXFyueB-PU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A learning rate function has been defined which decreases the learning rate in a geometric progreesion manner. It constantly devides the learning rate by div_step until it is greater than stop."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q9Sw4ymFRo8F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lr_iter(start, stop, div_step) :\n",
        "    while start >= stop:\n",
        "        yield start\n",
        "        start/= div_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEx8yTX8B-PW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training is started for 10 epochs for every learning rate. After every 10 epochs, the learning rate is divided by div_step which is specified."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iQikrYO_Rvlr",
        "outputId": "e4a91495-5b89-4a11-9695-8ffa291349de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3267
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Started training...\")\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "for i in lr_iter(0.005, 0.0001, 2):\n",
        "    model.optimizer.lr = i\n",
        "    print (\"Learning rate = \"+str(i))\n",
        "    model.fit_generator(generator=train_gen, epochs=EPOCHS,\n",
        "                   validation_data = val_gen, use_multiprocessing=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started training...\n",
            "Learning rate = 0.005\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/15\n",
            "263/263 [==============================] - 11s 43ms/step - loss: 0.8998 - acc: 0.6167 - val_loss: 0.7104 - val_acc: 0.6831\n",
            "Epoch 2/15\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.7070 - acc: 0.7081 - val_loss: 0.7293 - val_acc: 0.7114\n",
            "Epoch 3/15\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.6392 - acc: 0.7525 - val_loss: 0.7173 - val_acc: 0.6914\n",
            "Epoch 4/15\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.5942 - acc: 0.7694 - val_loss: 0.6381 - val_acc: 0.7318\n",
            "Epoch 5/15\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.5696 - acc: 0.7897 - val_loss: 0.5422 - val_acc: 0.8021\n",
            "Epoch 6/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.5323 - acc: 0.8025 - val_loss: 0.4360 - val_acc: 0.8224\n",
            "Epoch 7/15\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.5220 - acc: 0.8080 - val_loss: 0.4664 - val_acc: 0.8124\n",
            "Epoch 8/15\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.5019 - acc: 0.8099 - val_loss: 0.4440 - val_acc: 0.8336\n",
            "Epoch 9/15\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.4960 - acc: 0.8142 - val_loss: 0.4593 - val_acc: 0.8081\n",
            "Epoch 10/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.4746 - acc: 0.8214 - val_loss: 0.4274 - val_acc: 0.8349\n",
            "Epoch 11/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.4739 - acc: 0.8254 - val_loss: 0.4011 - val_acc: 0.8451\n",
            "Epoch 12/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.4617 - acc: 0.8291 - val_loss: 0.4252 - val_acc: 0.8278\n",
            "Epoch 13/15\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.4490 - acc: 0.8328 - val_loss: 0.4529 - val_acc: 0.8069\n",
            "Epoch 14/15\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.4340 - acc: 0.8385 - val_loss: 0.5298 - val_acc: 0.7667\n",
            "Epoch 15/15\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.4302 - acc: 0.8391 - val_loss: 0.4415 - val_acc: 0.8376\n",
            "Learning rate = 0.0025\n",
            "Epoch 1/15\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.4272 - acc: 0.8385 - val_loss: 0.4070 - val_acc: 0.8433\n",
            "Epoch 2/15\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.4218 - acc: 0.8436 - val_loss: 0.4529 - val_acc: 0.8153\n",
            "Epoch 3/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.4138 - acc: 0.8435 - val_loss: 0.4059 - val_acc: 0.8489\n",
            "Epoch 4/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.4074 - acc: 0.8497 - val_loss: 0.4097 - val_acc: 0.8347\n",
            "Epoch 5/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3893 - acc: 0.8538 - val_loss: 0.3968 - val_acc: 0.8492\n",
            "Epoch 6/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3896 - acc: 0.8546 - val_loss: 0.3752 - val_acc: 0.8621\n",
            "Epoch 7/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3868 - acc: 0.8531 - val_loss: 0.3714 - val_acc: 0.8506\n",
            "Epoch 8/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3751 - acc: 0.8606 - val_loss: 0.3647 - val_acc: 0.8588\n",
            "Epoch 9/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3756 - acc: 0.8606 - val_loss: 0.5148 - val_acc: 0.7883\n",
            "Epoch 10/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3733 - acc: 0.8613 - val_loss: 0.3974 - val_acc: 0.8364\n",
            "Epoch 11/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3556 - acc: 0.8661 - val_loss: 0.3580 - val_acc: 0.8631\n",
            "Epoch 12/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3558 - acc: 0.8699 - val_loss: 0.3752 - val_acc: 0.8561\n",
            "Epoch 13/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3521 - acc: 0.8669 - val_loss: 0.3771 - val_acc: 0.8554\n",
            "Epoch 14/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3488 - acc: 0.8703 - val_loss: 0.3710 - val_acc: 0.8551\n",
            "Epoch 15/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3503 - acc: 0.8698 - val_loss: 0.3689 - val_acc: 0.8547\n",
            "Learning rate = 0.00125\n",
            "Epoch 1/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3480 - acc: 0.8766 - val_loss: 0.4638 - val_acc: 0.8250\n",
            "Epoch 2/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3373 - acc: 0.8756 - val_loss: 0.4841 - val_acc: 0.8132\n",
            "Epoch 3/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3339 - acc: 0.8749 - val_loss: 0.3479 - val_acc: 0.8712\n",
            "Epoch 4/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3209 - acc: 0.8776 - val_loss: 0.3488 - val_acc: 0.8724\n",
            "Epoch 5/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3248 - acc: 0.8786 - val_loss: 0.3479 - val_acc: 0.8765\n",
            "Epoch 6/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3114 - acc: 0.8846 - val_loss: 0.5129 - val_acc: 0.8069\n",
            "Epoch 7/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3195 - acc: 0.8825 - val_loss: 0.4270 - val_acc: 0.8456\n",
            "Epoch 8/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.3085 - acc: 0.8832 - val_loss: 0.3488 - val_acc: 0.8765\n",
            "Epoch 9/15\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.3184 - acc: 0.8838 - val_loss: 0.3575 - val_acc: 0.8712\n",
            "Epoch 10/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2969 - acc: 0.8915 - val_loss: 0.3662 - val_acc: 0.8632\n",
            "Epoch 11/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2978 - acc: 0.8899 - val_loss: 0.3536 - val_acc: 0.8636\n",
            "Epoch 12/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.3015 - acc: 0.8887 - val_loss: 0.3401 - val_acc: 0.8757\n",
            "Epoch 13/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2944 - acc: 0.8881 - val_loss: 0.3914 - val_acc: 0.8597\n",
            "Epoch 14/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2848 - acc: 0.8918 - val_loss: 0.4047 - val_acc: 0.8572\n",
            "Epoch 15/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2922 - acc: 0.8891 - val_loss: 0.5209 - val_acc: 0.8108\n",
            "Learning rate = 0.000625\n",
            "Epoch 1/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2883 - acc: 0.8901 - val_loss: 0.3372 - val_acc: 0.8747\n",
            "Epoch 2/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2811 - acc: 0.8912 - val_loss: 0.6073 - val_acc: 0.8097\n",
            "Epoch 3/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2833 - acc: 0.8937 - val_loss: 0.5346 - val_acc: 0.8257\n",
            "Epoch 4/15\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.2880 - acc: 0.8895 - val_loss: 0.3641 - val_acc: 0.8717\n",
            "Epoch 5/15\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.2753 - acc: 0.8964 - val_loss: 0.4614 - val_acc: 0.8401\n",
            "Epoch 6/15\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 0.2731 - acc: 0.8965 - val_loss: 0.3593 - val_acc: 0.8743\n",
            "Epoch 7/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2762 - acc: 0.9004 - val_loss: 0.3428 - val_acc: 0.8793\n",
            "Epoch 8/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2592 - acc: 0.8997 - val_loss: 0.3524 - val_acc: 0.8719\n",
            "Epoch 9/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2610 - acc: 0.9027 - val_loss: 0.3591 - val_acc: 0.8793\n",
            "Epoch 10/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2588 - acc: 0.9022 - val_loss: 0.3424 - val_acc: 0.8781\n",
            "Epoch 11/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2596 - acc: 0.9052 - val_loss: 0.3540 - val_acc: 0.8783\n",
            "Epoch 12/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2892 - acc: 0.8917 - val_loss: 0.3653 - val_acc: 0.8674\n",
            "Epoch 13/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2655 - acc: 0.9029 - val_loss: 0.4484 - val_acc: 0.8440\n",
            "Epoch 14/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2581 - acc: 0.9019 - val_loss: 0.3462 - val_acc: 0.8753\n",
            "Epoch 15/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2533 - acc: 0.9033 - val_loss: 0.3386 - val_acc: 0.8825\n",
            "Learning rate = 0.0003125\n",
            "Epoch 1/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2447 - acc: 0.9088 - val_loss: 0.3731 - val_acc: 0.8675\n",
            "Epoch 2/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2921 - acc: 0.8907 - val_loss: 0.3814 - val_acc: 0.8778\n",
            "Epoch 3/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2606 - acc: 0.9049 - val_loss: 0.3289 - val_acc: 0.8828\n",
            "Epoch 4/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2563 - acc: 0.9055 - val_loss: 0.3726 - val_acc: 0.8635\n",
            "Epoch 5/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2408 - acc: 0.9082 - val_loss: 0.3342 - val_acc: 0.8808\n",
            "Epoch 6/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2390 - acc: 0.9120 - val_loss: 0.3525 - val_acc: 0.8808\n",
            "Epoch 7/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2345 - acc: 0.9140 - val_loss: 0.3383 - val_acc: 0.8853\n",
            "Epoch 8/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2374 - acc: 0.9069 - val_loss: 0.3555 - val_acc: 0.8847\n",
            "Epoch 9/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2301 - acc: 0.9146 - val_loss: 0.3631 - val_acc: 0.8864\n",
            "Epoch 10/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2257 - acc: 0.9138 - val_loss: 0.3942 - val_acc: 0.8744\n",
            "Epoch 11/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2371 - acc: 0.9134 - val_loss: 0.3722 - val_acc: 0.8789\n",
            "Epoch 12/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2330 - acc: 0.9151 - val_loss: 0.3640 - val_acc: 0.8881\n",
            "Epoch 13/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2228 - acc: 0.9171 - val_loss: 0.4032 - val_acc: 0.8721\n",
            "Epoch 14/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2284 - acc: 0.9158 - val_loss: 0.4190 - val_acc: 0.8549\n",
            "Epoch 15/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2204 - acc: 0.9173 - val_loss: 0.3392 - val_acc: 0.8832\n",
            "Learning rate = 0.00015625\n",
            "Epoch 1/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2260 - acc: 0.9153 - val_loss: 0.3650 - val_acc: 0.8760\n",
            "Epoch 2/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2312 - acc: 0.9142 - val_loss: 0.4772 - val_acc: 0.8421\n",
            "Epoch 3/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2203 - acc: 0.9178 - val_loss: 0.3466 - val_acc: 0.8840\n",
            "Epoch 4/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2258 - acc: 0.9161 - val_loss: 0.3662 - val_acc: 0.8878\n",
            "Epoch 5/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2257 - acc: 0.9182 - val_loss: 0.4040 - val_acc: 0.8672\n",
            "Epoch 6/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2216 - acc: 0.9199 - val_loss: 0.4343 - val_acc: 0.8678\n",
            "Epoch 7/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2190 - acc: 0.9170 - val_loss: 0.5336 - val_acc: 0.8399\n",
            "Epoch 8/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2085 - acc: 0.9217 - val_loss: 0.4055 - val_acc: 0.8679\n",
            "Epoch 9/15\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2174 - acc: 0.9188 - val_loss: 0.3628 - val_acc: 0.8792\n",
            "Epoch 10/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2080 - acc: 0.9234 - val_loss: 0.4131 - val_acc: 0.8668\n",
            "Epoch 11/15\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2126 - acc: 0.9204 - val_loss: 0.3943 - val_acc: 0.8744\n",
            "Epoch 12/15\n",
            "263/263 [==============================] - 8s 29ms/step - loss: 0.2099 - acc: 0.9228 - val_loss: 0.3759 - val_acc: 0.8838\n",
            "Epoch 13/15\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.2228 - acc: 0.9171 - val_loss: 0.3803 - val_acc: 0.8815\n",
            "Epoch 14/15\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.2107 - acc: 0.9231 - val_loss: 0.3665 - val_acc: 0.8894\n",
            "Epoch 15/15\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 0.2144 - acc: 0.9192 - val_loss: 0.4034 - val_acc: 0.8783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n0tGulZjB-PZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model is saved with training accuracy as 90% and validation accuracy as 89%."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pXAm6Z5pcLl6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/gdrive/My Drive/MIDAS-CV-TASK/model-90-89.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "621xdlGSGjTo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}