{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for dumping and loading pickle files of exceedingly large sizes\n",
    "\n",
    "Reads data byte by byte and writes data byte by byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MacOSFile(object):\n",
    "\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        return getattr(self.f, item)\n",
    "\n",
    "    def read(self, n):\n",
    "        if n >= (1 << 31):\n",
    "            buffer = bytearray(n)\n",
    "            idx = 0\n",
    "            while idx < n:\n",
    "                batch_size = min(n - idx, 1 << 31 - 1)\n",
    "                buffer[idx:idx + batch_size] = self.f.read(batch_size)\n",
    "                idx += batch_size\n",
    "            return buffer\n",
    "        return self.f.read(n)\n",
    "\n",
    "    def write(self, buffer):\n",
    "        n = len(buffer)\n",
    "        print(\"writing total_bytes=%s...\" % n, flush=True)\n",
    "        idx = 0\n",
    "        while idx < n:\n",
    "            batch_size = min(n - idx, 1 << 31 - 1)\n",
    "            print(\"writing bytes [%s, %s)... \" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "            self.f.write(buffer[idx:idx + batch_size])\n",
    "            print(\"done.\", flush=True)\n",
    "            idx += batch_size\n",
    "\n",
    "\n",
    "def pickle_dump(obj, file_path):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        return pickle.dump(obj, MacOSFile(f), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def pickle_load(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(MacOSFile(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading training image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle_load('./data/train_image.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pickle_load('./data/train_label.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "8000\n",
      "<class 'list'>\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(len(train_data))\n",
    "print(type(train_data[0]))\n",
    "print(len(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(type(train_label))\n",
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 2, 3, 6}\n",
      "label 0:  2000\n",
      "label 2:  2000\n",
      "label 3:  2000\n",
      "label 6:  2000\n"
     ]
    }
   ],
   "source": [
    "st = set()\n",
    "ct0 = 0\n",
    "ct2 = 0\n",
    "ct3 = 0\n",
    "ct6 = 0\n",
    "for x in train_label:\n",
    "    st.add(x)\n",
    "    if x == 0:\n",
    "        ct0 += 1\n",
    "    if x == 2:\n",
    "        ct2 += 1\n",
    "    if x == 3:\n",
    "        ct3 += 1\n",
    "    if x == 6:\n",
    "        ct6 += 1\n",
    "print(st)\n",
    "print(\"label 0: \", ct0)\n",
    "print(\"label 2: \", ct2)\n",
    "print(\"label 3: \", ct3)\n",
    "print(\"label 6: \", ct6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset has 8000 lists of size=784. A rough assumption is that these might be images which have been flattened. But we may be wrong!! For this, we have to get the factors of 784(which might be the dimensions of the image).\n",
    "\n",
    "1 × 784 = 784\n",
    "\n",
    "2 × 392 = 784\n",
    "\n",
    "4 × 196 = 784\n",
    "\n",
    "7 × 112 = 784\n",
    "\n",
    "8 × 98 = 784\n",
    "\n",
    "14 × 56 = 784\n",
    "\n",
    "16 × 49 = 784\n",
    "\n",
    "28 × 28 = 784\n",
    "\n",
    "Lets try 28 x 28 images first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = train_data[2314] #Any random image chosen(not important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = np.array(image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = np.reshape(image_test , (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_test, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola!! It seems we were right all along. These are actually images of size 28 x 28 pixels. We plot some more images and get the idea that these are images of clothes. Especially upper body clothes. Using our previous knowledge in the field of Deep Learning and Computer Vision, we come to the conclusion that this dataset is a subset of the FashionMNIST dataset. \n",
    "\n",
    "However, since we are not allowed to augment the dataset using external sources, we wont be doing that at all. However, this dataset has only 2000 images for 4 classes. We will have to augment it as the original dataset contained around 6000 images for 10 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the dataset properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_for_shuffle = []\n",
    "for i in range(len(train_data)):\n",
    "    tup = (train_data[i], train_label[i])\n",
    "    temp_for_shuffle.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(temp_for_shuffle)\n",
    "shuffle(temp_for_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the shuffled dataset into numpy arrays of X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(len(temp_for_shuffle)):\n",
    "    y.append(temp_for_shuffle[i][1])\n",
    "    X.append(np.reshape(np.array(temp_for_shuffle[i][0]), (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since X contains grayscale images, we need to scale them between 0 and 1 before feeding them into any deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every deep learning model requires that the variable to be predicted should be one hot encoded. For that to be there, we need to change the labels from 0,2,3,6 to be 0,1,2,3. For this, we maintain a small dictionary and pickle it along with the augmented dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    0:0,\n",
    "    1:2,\n",
    "    2:3,\n",
    "    3:6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated labels in the form of [0,1,2,3]:  [1 1 2 ... 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_new = []\n",
    "for x in y:\n",
    "    if x == 0:\n",
    "        y_new.append(0)\n",
    "    if x == 2:\n",
    "        y_new.append(1)\n",
    "    if x == 3:\n",
    "        y_new.append(2)\n",
    "    if x == 6:\n",
    "        y_new.append(3)\n",
    "y = np.array(y_new)\n",
    "print(\"Updated labels in the form of [0,1,2,3]: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = np.max(y) + 1\n",
    "y_new = np.eye(n_values)[y]\n",
    "y = y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n",
      "(8000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(y[2314]) #Any random number(doesn't matter)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the dataset using rotation and flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pick a random degree of rotation between 25% on the left and 25% on the right\n",
    "\"\"\"\n",
    "def random_rotation(image_array: ndarray):\n",
    "    random_degree = random.uniform(-25, 25)\n",
    "    return sk.transform.rotate(image_array, random_degree)\n",
    "\n",
    "\"\"\"\n",
    "Vertical flipping is as easy as flipping the image array of pixels !\n",
    "\"\"\"\n",
    "def vertical_flip(image_array: ndarray):\n",
    "    return image_array[::-1, :]\n",
    "\n",
    "#dictionary of the transformations we defined earlier\n",
    "available_transformations = {\n",
    "    'rotate': random_rotation,\n",
    "    'vertical_flip': vertical_flip\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting the dataset using flipping and rotation and then appending duplicate labels according to the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = []\n",
    "y_new = []\n",
    "for i in range(X.shape[0]):\n",
    "    image_to_transform = X[i]\n",
    "\n",
    "    rotated = available_transformations['rotate'](image_to_transform)\n",
    "    vertical_flipped = available_transformations['vertical_flip'](image_to_transform)\n",
    "    #rot_and_flipped = available_transformations['vertical_flip'](rotated)\n",
    "    \n",
    "    X_new.append(rotated)\n",
    "    X_new.append(vertical_flipped)\n",
    "    X_new.append(image_to_transform)\n",
    "    \n",
    "    y_new.append(y[i])\n",
    "    y_new.append(y[i])\n",
    "    y_new.append(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (24000, 28, 28)\n",
      "y shape:  (24000, 4)\n"
     ]
    }
   ],
   "source": [
    "X = X_new\n",
    "y = y_new\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rehsaping X because Convolutional layers take as input 4D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X , (24000,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (24000, 28, 28, 1)\n",
      "y shape:  (24000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (16800, 28, 28, 1)\n",
      "y_train shape:  (16800, 4)\n",
      "X_val shape:  (7200, 28, 28, 1)\n",
      "y_val shape:  (7200, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_val shape: \", X_val.shape)\n",
    "print(\"y_val shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping the augmented dataset in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=151296376...\n",
      "writing bytes [0, 151296376)... done.\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    'X_train': X_train,\n",
    "    'X_val': X_val,\n",
    "    'y_train': y_train,\n",
    "    'y_val': y_val,\n",
    "    'dict': dict\n",
    "}\n",
    "pickle_dump(dataset, './data/dataset_large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
